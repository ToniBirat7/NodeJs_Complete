{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** Predicting red and white wine quality from our database\n",
    "\n",
    "- Import the red wine data into a database such as MariaDB (do this outside the pipeline)\n",
    "- Import the white wine data into a database such as MariaDB (do this outside the pipeline)\n",
    "- Allow the pipeline’s ingestion stage to now ingest both the red wine data and the white wine\n",
    "  data from the relational database, combine these into a single table and store them in a column\n",
    "  store at the end of the ingestion stage\n",
    "- Allow the pipeline’s validation stage to consume the data from the columnstore database and\n",
    "  then store this data directly into Redis (without further validation)\n",
    "- Allow the pipeline’s preparation stage to consume the data from redis and then split the data\n",
    "  into appropriate training and testing sub-sets (without further cleaning / preparation), storing\n",
    "  only the separate train_x, train_y, test_x and test_y split data in redis\n",
    "- Allow the pipeline’s training stage to retrieve the necessary separate training and test data\n",
    "  samples from redis (train_x, train_y, test_x and test_y), initiate an MLFlow run, fit the model\n",
    "  then store this model and any associated relevant data into redis\n",
    "- Allow the pipeline’s evaluation stage to evaluate the model using mean absolute error, mean\n",
    "  squared error, r2 score and median absolute error then end the run of the mlflow experiment.\n",
    "  The run should store the relevant parameters used to build the model as well as the evaluation\n",
    "  metrics used to assess the model quality on the test set of data, it should also log the model to\n",
    "  the relevant MLFlow data store.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingesting redwine and whitewine data and pushing to mariaDB after combining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6497"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "eng_conn = create_engine(\n",
    "    \"mysql+pymysql://birat:birat%2312345@localhost:3306/wine_db\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT * FROM whiteWine\n",
    "UNION\n",
    "SELECT * FROM redWine;\n",
    "\"\"\"\n",
    "\n",
    "wine = pd.read_sql(query, eng_conn, index_col='index')\n",
    "wine.to_sql(\"combinedWine\", eng_conn, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collection of simple helper functions for making life easy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import pickle\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "redis_conn = redis.Redis(host='127.0.0.1', port=6379)\n",
    "\n",
    "\n",
    "def store_pickle(key, obj):\n",
    "    redis_conn.set(key, pickle.dumps(obj))\n",
    "\n",
    "\n",
    "def retrieve_pickle(key):\n",
    "    return pickle.loads(redis_conn.get(key))\n",
    "\n",
    "\n",
    "def store_df(key, df):\n",
    "   \n",
    "    if isinstance(df, pd.Series):\n",
    "        df = df.to_frame()\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    buffer_reader = pa.BufferOutputStream()\n",
    "    pq.write_table(table, buffer_reader)\n",
    "    serialized_df = buffer_reader.getvalue().to_pybytes()\n",
    "    redis_conn.set(key, serialized_df)\n",
    "\n",
    "\n",
    "def retrieve_df(key):\n",
    "    data = redis_conn.get(key)\n",
    "    buffer_reader = pa.BufferReader(data)\n",
    "    parquet_table = pq.read_table(buffer_reader)\n",
    "    return parquet_table.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting data from mariaDB and storing in redis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "eng_conn = create_engine(\n",
    "    \"mysql+pymysql://birat:birat%2312345@localhost:3306/wine_db\")\n",
    "\n",
    "query = \"SELECT * FROM combinedWine\"\n",
    "wine = pd.read_sql(query, eng_conn, index_col='index')\n",
    "\n",
    "for col in wine.columns:\n",
    "    if wine[col].dtype == np.dtype('object'):\n",
    "        raise TypeError(f'Column {col} is of type object')\n",
    "\n",
    "    if wine[col].isna().sum() > 0:\n",
    "        raise warnings.warn(f'Column {col} contains null values')\n",
    "\n",
    "store_df('wine_key', wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving df from redis store and splitting into train_x, train_y, test_x, test_y and storing them in redis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x serialized and stored to redis.\n",
      "train_y serialized and stored to redis.\n",
      "test_x serialized and stored to redis.\n",
      "test_y serialized and stored to redis.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine_df = retrieve_df('wine_key')\n",
    "\n",
    "FEATURES = [col for col in wine_df.columns if col != 'quality']\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    wine_df[FEATURES], wine_df['quality'], random_state=59)\n",
    "\n",
    "data_dict = {'train_x': train_x, 'train_y': train_y,\n",
    "             'test_x': test_x, 'test_y': test_y}\n",
    "for key in data_dict.keys():\n",
    "    store_df(key, data_dict[key])\n",
    "    print(f'{key} serialized and stored to redis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving train_x and train_y and training RandomForestRegressor and export model, model params and run_id to redis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train = retrieve_df('train_x')\n",
    "y_train = retrieve_df('train_y')\n",
    "\n",
    "# Enable MLflow tracking\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")  \n",
    "mlflow.set_experiment(\"Wine_Quality_Prediction\")\n",
    "\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    n_estimators = 1000\n",
    "    max_depth = 15\n",
    "    random_state = 5\n",
    "\n",
    "    clf = RandomForestRegressor(\n",
    "        n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "    clf.fit(X_train, y_train)\n",
    "    store_pickle('rfr_model', clf)\n",
    "    hyperparameters = {'n_estimators': n_estimators,\n",
    "                       'max_depth': max_depth, 'random_state': random_state}\n",
    "    store_pickle('rfr_hyperparameters', hyperparameters)\n",
    "    store_pickle('rfr_run_id', run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving model, model params and run id and logging model metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow.pyfunc\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, median_absolute_error\n",
    "\n",
    "clf = retrieve_pickle('rfr_model')\n",
    "X_test = retrieve_df('test_x')\n",
    "y_test = retrieve_df('test_y')\n",
    "hyperparameters = retrieve_pickle('rfr_hyperparameters')\n",
    "run_id = retrieve_pickle('rfr_run_id')\n",
    "\n",
    "# Enable MLflow tracking\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")  # or leave as default local\n",
    "\n",
    "mlflow.set_experiment(\"Wine_Quality_Prediction\")\n",
    "with mlflow.start_run(run_id=run_id) as run:\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    metrics = {\n",
    "        'abs_error': mean_absolute_error(y_pred, y_test),\n",
    "        'sq_error': mean_squared_error(y_pred, y_test),\n",
    "        'r2': r2_score(y_pred, y_test),\n",
    "        'med_abs_error': median_absolute_error(y_pred, y_test)\n",
    "    }\n",
    "\n",
    "    # Tracks hyperparameters\n",
    "    mlflow.log_params(hyperparameters)\n",
    "\n",
    "    # Records performance\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    model_path = \"wine_quality_model\"\n",
    "    joblib.dump(clf, model_path + \".pkl\")\n",
    "    mlflow.log_artifact(model_path + \".pkl\")\n",
    "\n",
    "    # Logs and optionally registers the model.\n",
    "    mlflow.sklearn.log_model(clf, \"model\")\n",
    "\n",
    "    model_info = mlflow.register_model(\n",
    "        model_uri=f\"runs:/{run.info.run_id}/model\",\n",
    "        name=\"WineQualityRandomForestModel\"\n",
    "    )\n",
    "\n",
    "    print(f\"Model registered with name: {model_info.name}\")\n",
    "    print(f\"Model version: {model_info.version}\")\n",
    "    print(f\"Run ID: {run.info.run_id}\")\n",
    "\n",
    "\n",
    "# Assuming model_info is a ModelVersion object\n",
    "model_name = model_info.name  # Get the registered model name\n",
    "model_version = model_info.version  # Get the model version\n",
    "\n",
    "# Construct the model URI for the Model Registry\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "print(model_name)\n",
    "print(model_version)\n",
    "print(model_uri)\n",
    "print(\"Loading model from Model Registry...\")\n",
    "# Load the model from the Model Registry\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "# Create result DataFrame\n",
    "result = pd.DataFrame(X_test)\n",
    "result[\"actual_class\"] = y_test\n",
    "result[\"predicted_class\"] = predictions\n",
    "\n",
    "print(result[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** LAX to JFK Flight delays prediction\n",
    "\n",
    "- Using the previous Airline sample data which we have used in prior exercises\n",
    "  (https://developer.ibm.com/exchanges/data/all/airline/) , plan out and implement a Machine\n",
    "  Learning Pipeline using Airflow and MLFlow\n",
    "- To create a basic plan for this pipeline you should at least:\n",
    "  - Produce an appropriate data model that describes the data (such as an ERD)\n",
    "    - This data model should as a minimum:\n",
    "      - Capture the attributes (columns) each relation (table) contains, along with their types.\n",
    "      - It should also attempt to capture any relationships between relations (tables). Note: if there is only one table with no relations with another, then this step\n",
    "    - You may also wish to attempt to produce a Data Structure Diagram, which differs from ERDs in that it allows us to identify the relationships between attributes within an entity\n",
    "    - Any appropriate diagramming / CASE software may be used for this task (e.g. Draw.io, Visio, VisualParadigm, etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To create a basic plan for this pipeline you should at least:\n",
    "  - Produce an appropriate DAG pipeline plan that specifies the sequence of tasks that will be performed\n",
    "  - Produce an appropriate DAG pipeline plan that specifies the sequence of operations that must be performed within each task (e.g. when ingesting the data, what steps need to be taken, and in what order?)\n",
    "  - Detail what tools / technologies will be needed at each stage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To implement the pipeline you should at least:\n",
    "  - Provide a means of appropriately ingesting the initial dataset from a relational database\n",
    "  - Provide a means of appropriately logging the attempt at training and evaluating the model to MLFlow\n",
    "  - Provide a means of storing the trained and evaluated model coupled along with the MLFlow results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "eng_conn = create_engine(\n",
    "    \"engine = create_engine('mysql+pymysql://root:sandeshpass@localhost:3308/Airline\")\n",
    "airline = pd.read_sql('SELECT * FROM LAXTOJFK', eng_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('airbnb.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(data.columns)\n",
    "usable_cols = [col for col in cols if data[col].isna().sum() <=\n",
    "               len(data[col])*0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>Reporting_Airline</th>\n",
       "      <th>DOT_ID_Reporting_Airline</th>\n",
       "      <th>IATA_CODE_Reporting_Airline</th>\n",
       "      <th>Flight_Number_Reporting_Airline</th>\n",
       "      <th>OriginAirportID</th>\n",
       "      <th>OriginAirportSeqID</th>\n",
       "      <th>OriginCityMarketID</th>\n",
       "      <th>Origin</th>\n",
       "      <th>OriginCityName</th>\n",
       "      <th>OriginState</th>\n",
       "      <th>OriginStateFips</th>\n",
       "      <th>OriginStateName</th>\n",
       "      <th>OriginWac</th>\n",
       "      <th>DestAirportID</th>\n",
       "      <th>DestAirportSeqID</th>\n",
       "      <th>DestCityMarketID</th>\n",
       "      <th>Dest</th>\n",
       "      <th>DestCityName</th>\n",
       "      <th>DestState</th>\n",
       "      <th>DestStateFips</th>\n",
       "      <th>DestStateName</th>\n",
       "      <th>DestWac</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>DepDelayMinutes</th>\n",
       "      <th>DepDel15</th>\n",
       "      <th>DepartureDelayGroups</th>\n",
       "      <th>DepTimeBlk</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>ArrDelayMinutes</th>\n",
       "      <th>ArrDel15</th>\n",
       "      <th>ArrivalDelayGroups</th>\n",
       "      <th>ArrTimeBlk</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CRSElapsedTime</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>Flights</th>\n",
       "      <th>Distance</th>\n",
       "      <th>DistanceGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1998-01-02</td>\n",
       "      <td>NW</td>\n",
       "      <td>19386</td>\n",
       "      <td>NW</td>\n",
       "      <td>675</td>\n",
       "      <td>13487</td>\n",
       "      <td>1348701</td>\n",
       "      <td>31650</td>\n",
       "      <td>MSP</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>63</td>\n",
       "      <td>14869</td>\n",
       "      <td>1486902</td>\n",
       "      <td>34614</td>\n",
       "      <td>SLC</td>\n",
       "      <td>Salt Lake City, UT</td>\n",
       "      <td>UT</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Utah</td>\n",
       "      <td>87</td>\n",
       "      <td>1640</td>\n",
       "      <td>1659.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1600-1659</td>\n",
       "      <td>1836</td>\n",
       "      <td>1859.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1800-1859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>991.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2009-05-28</td>\n",
       "      <td>FL</td>\n",
       "      <td>20437</td>\n",
       "      <td>FL</td>\n",
       "      <td>671</td>\n",
       "      <td>13342</td>\n",
       "      <td>1334202</td>\n",
       "      <td>33342</td>\n",
       "      <td>MKE</td>\n",
       "      <td>Milwaukee, WI</td>\n",
       "      <td>WI</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>45</td>\n",
       "      <td>13204</td>\n",
       "      <td>1320401</td>\n",
       "      <td>31454</td>\n",
       "      <td>MCO</td>\n",
       "      <td>Orlando, FL</td>\n",
       "      <td>FL</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33</td>\n",
       "      <td>1204</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1200-1259</td>\n",
       "      <td>1541</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500-1559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>2013-06-29</td>\n",
       "      <td>MQ</td>\n",
       "      <td>20398</td>\n",
       "      <td>MQ</td>\n",
       "      <td>3297</td>\n",
       "      <td>11921</td>\n",
       "      <td>1192102</td>\n",
       "      <td>31921</td>\n",
       "      <td>GJT</td>\n",
       "      <td>Grand Junction, CO</td>\n",
       "      <td>CO</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>82</td>\n",
       "      <td>11298</td>\n",
       "      <td>1129803</td>\n",
       "      <td>30194</td>\n",
       "      <td>DFW</td>\n",
       "      <td>Dallas/Fort Worth, TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>74</td>\n",
       "      <td>1630</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600-1659</td>\n",
       "      <td>1945</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1900-1959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>773.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>DL</td>\n",
       "      <td>19790</td>\n",
       "      <td>DL</td>\n",
       "      <td>1806</td>\n",
       "      <td>12892</td>\n",
       "      <td>1289201</td>\n",
       "      <td>32575</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>California</td>\n",
       "      <td>91</td>\n",
       "      <td>11433</td>\n",
       "      <td>1143301</td>\n",
       "      <td>31295</td>\n",
       "      <td>DTW</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>MI</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>43</td>\n",
       "      <td>1305</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1300-1359</td>\n",
       "      <td>2035</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2000-2059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>2006-01-15</td>\n",
       "      <td>US</td>\n",
       "      <td>20355</td>\n",
       "      <td>US</td>\n",
       "      <td>465</td>\n",
       "      <td>11618</td>\n",
       "      <td>1161801</td>\n",
       "      <td>31703</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark, NJ</td>\n",
       "      <td>NJ</td>\n",
       "      <td>34.0</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>21</td>\n",
       "      <td>11057</td>\n",
       "      <td>1105702</td>\n",
       "      <td>31057</td>\n",
       "      <td>CLT</td>\n",
       "      <td>Charlotte, NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>37.0</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>36</td>\n",
       "      <td>1820</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1800-1859</td>\n",
       "      <td>2026</td>\n",
       "      <td>2058.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000-2059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate Reporting_Airline  \\\n",
       "0  1998        1      1           2          5  1998-01-02                NW   \n",
       "1  2009        2      5          28          4  2009-05-28                FL   \n",
       "2  2013        2      6          29          6  2013-06-29                MQ   \n",
       "3  2010        3      8          31          2  2010-08-31                DL   \n",
       "4  2006        1      1          15          7  2006-01-15                US   \n",
       "\n",
       "   DOT_ID_Reporting_Airline IATA_CODE_Reporting_Airline  \\\n",
       "0                     19386                          NW   \n",
       "1                     20437                          FL   \n",
       "2                     20398                          MQ   \n",
       "3                     19790                          DL   \n",
       "4                     20355                          US   \n",
       "\n",
       "   Flight_Number_Reporting_Airline  OriginAirportID  OriginAirportSeqID  \\\n",
       "0                              675            13487             1348701   \n",
       "1                              671            13342             1334202   \n",
       "2                             3297            11921             1192102   \n",
       "3                             1806            12892             1289201   \n",
       "4                              465            11618             1161801   \n",
       "\n",
       "   OriginCityMarketID Origin      OriginCityName OriginState  OriginStateFips  \\\n",
       "0               31650    MSP     Minneapolis, MN          MN             27.0   \n",
       "1               33342    MKE       Milwaukee, WI          WI             55.0   \n",
       "2               31921    GJT  Grand Junction, CO          CO              8.0   \n",
       "3               32575    LAX     Los Angeles, CA          CA              6.0   \n",
       "4               31703    EWR          Newark, NJ          NJ             34.0   \n",
       "\n",
       "  OriginStateName  OriginWac  DestAirportID  DestAirportSeqID  \\\n",
       "0       Minnesota         63          14869           1486902   \n",
       "1       Wisconsin         45          13204           1320401   \n",
       "2        Colorado         82          11298           1129803   \n",
       "3      California         91          11433           1143301   \n",
       "4      New Jersey         21          11057           1105702   \n",
       "\n",
       "   DestCityMarketID Dest           DestCityName DestState  DestStateFips  \\\n",
       "0             34614  SLC     Salt Lake City, UT        UT           49.0   \n",
       "1             31454  MCO            Orlando, FL        FL           12.0   \n",
       "2             30194  DFW  Dallas/Fort Worth, TX        TX           48.0   \n",
       "3             31295  DTW            Detroit, MI        MI           26.0   \n",
       "4             31057  CLT          Charlotte, NC        NC           37.0   \n",
       "\n",
       "    DestStateName  DestWac  CRSDepTime  DepTime  DepDelay  DepDelayMinutes  \\\n",
       "0            Utah       87        1640   1659.0      19.0             19.0   \n",
       "1         Florida       33        1204   1202.0      -2.0              0.0   \n",
       "2           Texas       74        1630   1644.0      14.0             14.0   \n",
       "3        Michigan       43        1305   1305.0       0.0              0.0   \n",
       "4  North Carolina       36        1820   1911.0      51.0             51.0   \n",
       "\n",
       "   DepDel15  DepartureDelayGroups DepTimeBlk  CRSArrTime  ArrTime  ArrDelay  \\\n",
       "0       1.0                   1.0  1600-1659        1836   1859.0      23.0   \n",
       "1       0.0                  -1.0  1200-1259        1541   1541.0       0.0   \n",
       "2       0.0                   0.0  1600-1659        1945   1942.0      -3.0   \n",
       "3       0.0                   0.0  1300-1359        2035   2015.0     -20.0   \n",
       "4       1.0                   3.0  1800-1859        2026   2058.0      32.0   \n",
       "\n",
       "   ArrDelayMinutes  ArrDel15  ArrivalDelayGroups ArrTimeBlk  Cancelled  \\\n",
       "0             23.0       1.0                 1.0  1800-1859        0.0   \n",
       "1              0.0       0.0                 0.0  1500-1559        0.0   \n",
       "2              0.0       0.0                -1.0  1900-1959        0.0   \n",
       "3              0.0       0.0                -2.0  2000-2059        0.0   \n",
       "4             32.0       1.0                 2.0  2000-2059        0.0   \n",
       "\n",
       "   Diverted  CRSElapsedTime  ActualElapsedTime  Flights  Distance  \\\n",
       "0       0.0           176.0              180.0      1.0     991.0   \n",
       "1       0.0           157.0              159.0      1.0    1066.0   \n",
       "2       0.0           135.0              118.0      1.0     773.0   \n",
       "3       0.0           270.0              250.0      1.0    1979.0   \n",
       "4       0.0           126.0              107.0      1.0     529.0   \n",
       "\n",
       "   DistanceGroup  \n",
       "0              4  \n",
       "1              5  \n",
       "2              4  \n",
       "3              8  \n",
       "4              3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data[usable_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List DepDelayMinutes where ['ArrDel15'] == ['ArrDelay']\n",
    "delayed_flights = data[usable_cols][data['ArrDel15'] == data['ArrDelay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>Reporting_Airline</th>\n",
       "      <th>DOT_ID_Reporting_Airline</th>\n",
       "      <th>IATA_CODE_Reporting_Airline</th>\n",
       "      <th>Flight_Number_Reporting_Airline</th>\n",
       "      <th>OriginAirportID</th>\n",
       "      <th>OriginAirportSeqID</th>\n",
       "      <th>OriginCityMarketID</th>\n",
       "      <th>Origin</th>\n",
       "      <th>OriginCityName</th>\n",
       "      <th>OriginState</th>\n",
       "      <th>OriginStateFips</th>\n",
       "      <th>OriginStateName</th>\n",
       "      <th>OriginWac</th>\n",
       "      <th>DestAirportID</th>\n",
       "      <th>DestAirportSeqID</th>\n",
       "      <th>DestCityMarketID</th>\n",
       "      <th>Dest</th>\n",
       "      <th>DestCityName</th>\n",
       "      <th>DestState</th>\n",
       "      <th>DestStateFips</th>\n",
       "      <th>DestStateName</th>\n",
       "      <th>DestWac</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>DepDelayMinutes</th>\n",
       "      <th>DepDel15</th>\n",
       "      <th>DepartureDelayGroups</th>\n",
       "      <th>DepTimeBlk</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>ArrDelayMinutes</th>\n",
       "      <th>ArrDel15</th>\n",
       "      <th>ArrivalDelayGroups</th>\n",
       "      <th>ArrTimeBlk</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CRSElapsedTime</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>Flights</th>\n",
       "      <th>Distance</th>\n",
       "      <th>DistanceGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2009-05-28</td>\n",
       "      <td>FL</td>\n",
       "      <td>20437</td>\n",
       "      <td>FL</td>\n",
       "      <td>671</td>\n",
       "      <td>13342</td>\n",
       "      <td>1334202</td>\n",
       "      <td>33342</td>\n",
       "      <td>MKE</td>\n",
       "      <td>Milwaukee, WI</td>\n",
       "      <td>WI</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>45</td>\n",
       "      <td>13204</td>\n",
       "      <td>1320401</td>\n",
       "      <td>31454</td>\n",
       "      <td>MCO</td>\n",
       "      <td>Orlando, FL</td>\n",
       "      <td>FL</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33</td>\n",
       "      <td>1204</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1200-1259</td>\n",
       "      <td>1541</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500-1559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2004-12-21</td>\n",
       "      <td>WN</td>\n",
       "      <td>19393</td>\n",
       "      <td>WN</td>\n",
       "      <td>1111</td>\n",
       "      <td>10423</td>\n",
       "      <td>1042302</td>\n",
       "      <td>30423</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>74</td>\n",
       "      <td>11540</td>\n",
       "      <td>1154001</td>\n",
       "      <td>30615</td>\n",
       "      <td>ELP</td>\n",
       "      <td>El Paso, TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>74</td>\n",
       "      <td>1150</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1100-1159</td>\n",
       "      <td>1225</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200-1259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-10-11</td>\n",
       "      <td>WN</td>\n",
       "      <td>19393</td>\n",
       "      <td>WN</td>\n",
       "      <td>378</td>\n",
       "      <td>14107</td>\n",
       "      <td>1410701</td>\n",
       "      <td>30466</td>\n",
       "      <td>PHX</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>AZ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>81</td>\n",
       "      <td>13796</td>\n",
       "      <td>1379601</td>\n",
       "      <td>32457</td>\n",
       "      <td>OAK</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>California</td>\n",
       "      <td>91</td>\n",
       "      <td>650</td>\n",
       "      <td>650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0600-0659</td>\n",
       "      <td>850</td>\n",
       "      <td>850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0800-0859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1997</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1997-05-26</td>\n",
       "      <td>HP</td>\n",
       "      <td>19991</td>\n",
       "      <td>HP</td>\n",
       "      <td>2866</td>\n",
       "      <td>14107</td>\n",
       "      <td>1410701</td>\n",
       "      <td>30466</td>\n",
       "      <td>PHX</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>AZ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>81</td>\n",
       "      <td>14679</td>\n",
       "      <td>1467902</td>\n",
       "      <td>33570</td>\n",
       "      <td>SAN</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>California</td>\n",
       "      <td>91</td>\n",
       "      <td>1555</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500-1559</td>\n",
       "      <td>1659</td>\n",
       "      <td>1659.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600-1659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-11-26</td>\n",
       "      <td>WN</td>\n",
       "      <td>19393</td>\n",
       "      <td>WN</td>\n",
       "      <td>80</td>\n",
       "      <td>11259</td>\n",
       "      <td>1125902</td>\n",
       "      <td>30194</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>74</td>\n",
       "      <td>12191</td>\n",
       "      <td>1219101</td>\n",
       "      <td>31453</td>\n",
       "      <td>HOU</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>74</td>\n",
       "      <td>1000</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000-1059</td>\n",
       "      <td>1100</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1100-1159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate  \\\n",
       "1    2009        2      5          28          4  2009-05-28   \n",
       "53   2004        4     12          21          2  2004-12-21   \n",
       "56   2001        4     10          11          4  2001-10-11   \n",
       "61   1997        2      5          26          1  1997-05-26   \n",
       "184  2004        4     11          26          5  2004-11-26   \n",
       "\n",
       "    Reporting_Airline  DOT_ID_Reporting_Airline IATA_CODE_Reporting_Airline  \\\n",
       "1                  FL                     20437                          FL   \n",
       "53                 WN                     19393                          WN   \n",
       "56                 WN                     19393                          WN   \n",
       "61                 HP                     19991                          HP   \n",
       "184                WN                     19393                          WN   \n",
       "\n",
       "     Flight_Number_Reporting_Airline  OriginAirportID  OriginAirportSeqID  \\\n",
       "1                                671            13342             1334202   \n",
       "53                              1111            10423             1042302   \n",
       "56                               378            14107             1410701   \n",
       "61                              2866            14107             1410701   \n",
       "184                               80            11259             1125902   \n",
       "\n",
       "     OriginCityMarketID Origin OriginCityName OriginState  OriginStateFips  \\\n",
       "1                 33342    MKE  Milwaukee, WI          WI             55.0   \n",
       "53                30423    AUS     Austin, TX          TX             48.0   \n",
       "56                30466    PHX    Phoenix, AZ          AZ              4.0   \n",
       "61                30466    PHX    Phoenix, AZ          AZ              4.0   \n",
       "184               30194    DAL     Dallas, TX          TX             48.0   \n",
       "\n",
       "    OriginStateName  OriginWac  DestAirportID  DestAirportSeqID  \\\n",
       "1         Wisconsin         45          13204           1320401   \n",
       "53            Texas         74          11540           1154001   \n",
       "56          Arizona         81          13796           1379601   \n",
       "61          Arizona         81          14679           1467902   \n",
       "184           Texas         74          12191           1219101   \n",
       "\n",
       "     DestCityMarketID Dest   DestCityName DestState  DestStateFips  \\\n",
       "1               31454  MCO    Orlando, FL        FL           12.0   \n",
       "53              30615  ELP    El Paso, TX        TX           48.0   \n",
       "56              32457  OAK    Oakland, CA        CA            6.0   \n",
       "61              33570  SAN  San Diego, CA        CA            6.0   \n",
       "184             31453  HOU    Houston, TX        TX           48.0   \n",
       "\n",
       "    DestStateName  DestWac  CRSDepTime  DepTime  DepDelay  DepDelayMinutes  \\\n",
       "1         Florida       33        1204   1202.0      -2.0              0.0   \n",
       "53          Texas       74        1150   1150.0       0.0              0.0   \n",
       "56     California       91         650    650.0       0.0              0.0   \n",
       "61     California       91        1555   1555.0       0.0              0.0   \n",
       "184         Texas       74        1000   1005.0       5.0              5.0   \n",
       "\n",
       "     DepDel15  DepartureDelayGroups DepTimeBlk  CRSArrTime  ArrTime  ArrDelay  \\\n",
       "1         0.0                  -1.0  1200-1259        1541   1541.0       0.0   \n",
       "53        0.0                   0.0  1100-1159        1225   1225.0       0.0   \n",
       "56        0.0                   0.0  0600-0659         850    850.0       0.0   \n",
       "61        0.0                   0.0  1500-1559        1659   1659.0       0.0   \n",
       "184       0.0                   0.0  1000-1059        1100   1100.0       0.0   \n",
       "\n",
       "     ArrDelayMinutes  ArrDel15  ArrivalDelayGroups ArrTimeBlk  Cancelled  \\\n",
       "1                0.0       0.0                 0.0  1500-1559        0.0   \n",
       "53               0.0       0.0                 0.0  1200-1259        0.0   \n",
       "56               0.0       0.0                 0.0  0800-0859        0.0   \n",
       "61               0.0       0.0                 0.0  1600-1659        0.0   \n",
       "184              0.0       0.0                 0.0  1100-1159        0.0   \n",
       "\n",
       "     Diverted  CRSElapsedTime  ActualElapsedTime  Flights  Distance  \\\n",
       "1         0.0           157.0              159.0      1.0    1066.0   \n",
       "53        0.0            95.0               95.0      1.0     528.0   \n",
       "56        0.0           120.0              120.0      1.0     646.0   \n",
       "61        0.0            64.0               64.0      1.0     304.0   \n",
       "184       0.0            60.0               55.0      1.0     239.0   \n",
       "\n",
       "     DistanceGroup  \n",
       "1                5  \n",
       "53               3  \n",
       "56               3  \n",
       "61               2  \n",
       "184              1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the filtered data\n",
    "delayed_flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Produce an appropriate DAG pipeline plan that specifies the sequence of operations that\n",
    "  must be performed within each task (e.g. when ingesting the data, what steps need to be\n",
    "  taken, and in what order?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data:\n",
    "\n",
    "- A csv file of airline is loaded into pandas\n",
    "\n",
    "### 2. Data Preprocessing:\n",
    "\n",
    "- Columns are changed to lower memory hungry data type of float32 or int32 from their 64 bit counterparts\n",
    "- Rows with missing values are imputed with mean/mode of their respective rows\n",
    "- Since the dataset is huge only columns that are usable columns will be forwarded\n",
    "\n",
    "### 3. Data Ingestion:\n",
    "\n",
    "- A connection to mariadb and redis server is started\n",
    "- Data is stored in mariadb for future use.\n",
    "- Data is stored in redis for immediate use\n",
    "\n",
    "### 4. Model Development:\n",
    "\n",
    "- A connection to redis server is made\n",
    "- Data is splitted into X_train, y_train, X_test, y_test\n",
    "- XGBoost Model is fitted in the training data\n",
    "- Trained model and test data is pushed to the redis server\n",
    "\n",
    "### 5. Model Evaluation:\n",
    "\n",
    "- A connection to the redis server is made\n",
    "- Model and testing data is loaded into local variables\n",
    "- Model is evalueted using RMSE, MAE, r2 score, median absolute error\n",
    "- Model, metrics and its parameters are logged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from airflow import DAG\n",
    "from airflow.operators.bash import BashOperator\n",
    "from airflow.operators.python import PythonOperator\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pickle\n",
    "import redis\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "redis_conn = redis.Redis(host='127.0.0.1', port=6379)\n",
    "\n",
    "eng_conn = create_engine(\n",
    "    \"engine = create_engine('mysql+pymysql://root:biratpass@localhost:3308/Airline\")\n",
    "\n",
    "\n",
    "def store_pickle(key, obj):\n",
    "    redis_conn.set(key, pickle.dumps(obj))\n",
    "\n",
    "\n",
    "def retrieve_pickle(key):\n",
    "    return pickle.loads(redis_conn.get(key))\n",
    "\n",
    "\n",
    "def store_df(key, df):\n",
    "    # Used to_frame here because pa.Table only support dataframe and not series while pa support Series by using method like pa.Array this causes other errors later\n",
    "    if isinstance(df, pd.Series):\n",
    "        df = df.to_frame()\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    buffer_reader = pa.BufferOutputStream()\n",
    "    pq.write_table(table, buffer_reader)\n",
    "    serialized_df = buffer_reader.getvalue().to_pybytes()\n",
    "    redis_conn.set(key, serialized_df)\n",
    "\n",
    "\n",
    "def retrieve_df(key):\n",
    "    data = redis_conn.get(key)\n",
    "    buffer_reader = pa.BufferReader(data)\n",
    "    parquet_table = pq.read_table(buffer_reader)\n",
    "    return parquet_table.to_pandas()\n",
    "\n",
    "\n",
    "def read_csv():\n",
    "    df_airline = pd.read_csv('airbnb.csv')\n",
    "    df_airline.to_sql('Airline', con=eng_conn, if_exists=\"replace\")\n",
    "\n",
    "\n",
    "def preprocess_data():\n",
    "    query = \"SELECT * FROM Airline\"\n",
    "    df_airline = pd.read_sql(query, eng_conn)\n",
    "    usable_col = [col for col in df_airline.columns if df_airline[col].isna(\n",
    "    ).sum() <= len(df_airline[col])*0.1]\n",
    "    new_df = df_airline[usable_col]\n",
    "    numerical_cols = new_df.select_dtypes(include=['int64', 'float64'])\n",
    "    new_df['ArrDel15'] = new_df['ArrDel15'].dropna()\n",
    "    for col in numerical_cols:\n",
    "        if new_df[col].dtype == np.dtype('float64'):\n",
    "            new_df[col] = new_df[col].astype('float32')\n",
    "        elif new_df[col].dtype == np.dtype('int64'):\n",
    "            new_df[col] = new_df[col].astype('int32')\n",
    "        new_df[col] = new_df[col].fillna(new_df[col].mean())\n",
    "\n",
    "    categorical_cols = new_df.select_dtypes(include=['object'])\n",
    "    for col in categorical_cols:\n",
    "        new_df[col] = new_df[col].fillna('nan')\n",
    "        new_df[col] = new_df[col].astype('category')\n",
    "    # Storing new_df to mariadb\n",
    "    new_df.to_sql('airlinePreprocessed', con=eng_conn, if_exists=\"replace\")\n",
    "\n",
    "    # Storing new_df to redis\n",
    "    store_df('airlinePreprocessed', new_df)\n",
    "\n",
    "\n",
    "def model_training():\n",
    "    airline_df = retrieve_df('airlinePreprocessed')\n",
    "    FEATURES = [col for col in airline_df.columns if col != 'ArrDel15']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        airline_df[FEATURES], airline_df['ArrDel15'])\n",
    "\n",
    "    # Enable MLflow tracking\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"Airline_Flight_Delay_Prediction\")\n",
    "    with mlflow.start_run() as run:\n",
    "        xgb = XGBClassifier(enable_categorical=True)\n",
    "        xgb.fit(X_train, y_train)\n",
    "        store_pickle('xgb_model', xgb)\n",
    "        store_df('X_test', X_test)\n",
    "        store_df('y_test', y_test)\n",
    "        store_pickle('run_id', run.info.run_id)\n",
    "\n",
    "\n",
    "def model_evaluation():\n",
    "    X_test = retrieve_df('X_test')\n",
    "    y_test = retrieve_df('y_test')\n",
    "    xgb = retrieve_pickle('xgb_model')\n",
    "    run_id = retrieve_pickle('run_id')\n",
    "\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"Airline_Flight_Delay_Prediction\")\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id) as run:\n",
    "        y_pred = xgb.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(\n",
    "            y_test, y_pred, average='binary', pos_label=1)\n",
    "        f1 = f1_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "        recall = recall_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "\n",
    "default_args = {\n",
    "    \"owner\": \"birat gautam\",\n",
    "    \"depends_on_past\": False,\n",
    "    \"email\": [\"birat.gautam@mail.bcu.ac.uk\"],\n",
    "    \"email_on_failure\": False,\n",
    "    \"email_on_retry\": False,\n",
    "    \"retries\": 0,\n",
    "    \"retry_delay\": timedelta(minutes=5)\n",
    "}\n",
    "\n",
    "with DAG(\n",
    "    \"lab8\",\n",
    "    default_args=default_args,\n",
    "    description=\"A complete mlops pipeline for flight delay prediction\",\n",
    "    schedule_interval=timedelta(days=1),\n",
    "    start_date=datetime(2021, 10, 10),\n",
    "    catchup=False,\n",
    "    tags=[\"Airline\"]\n",
    ") as dag:\n",
    "    task1 = PythonOperator(\n",
    "        task_id=\"read_csv\",\n",
    "        python_callable=read_csv\n",
    "    )\n",
    "    task2 = BashOperator(\n",
    "        task_id=\"sleep_for_5_1\",\n",
    "        depends_on_past=False,\n",
    "        bash_command=\"sleep 5\",\n",
    "        retries=0\n",
    "    )\n",
    "    task3 = PythonOperator(\n",
    "        task_id=\"preprocess_data\",\n",
    "        python_callable=preprocess_data\n",
    "    )\n",
    "    task4 = BashOperator(\n",
    "        task_id=\"sleep_for_5_2\",\n",
    "        depends_on_past=False,\n",
    "        bash_command=\"sleep 5\",\n",
    "        retries=0\n",
    "    )\n",
    "    task5 = PythonOperator(\n",
    "        task_id=\"model_training\",\n",
    "        python_callable=model_training\n",
    "    )\n",
    "    task6 = BashOperator(\n",
    "        task_id=\"sleep_for_5_3\",\n",
    "        depends_on_past=False,\n",
    "        bash_command=\"sleep 5\",\n",
    "        retries=0\n",
    "    )\n",
    "    task7 = PythonOperator(\n",
    "        task_id=\"model_evaluation\",\n",
    "        python_callable=model_evaluation\n",
    "    )\n",
    "\n",
    "    task1 >> task2 >> task3 >> task4 >> task5 >> task6 >> task7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
